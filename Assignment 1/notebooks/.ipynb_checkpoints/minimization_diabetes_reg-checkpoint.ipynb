{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Applying data minimization to a trained regression ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will show how to perform data minimization for regression ML models using the minimization module.\n",
    "\n",
    "We will show you applying data minimization to a different trained regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load data\n",
    "QI parameter determines which features will be minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07090025  0.05068012 -0.08919748 ... -0.00259226 -0.01290868\n",
      "  -0.05492509]\n",
      " [-0.08179786  0.05068012  0.04229559 ...  0.1081111   0.04719048\n",
      "  -0.03835666]\n",
      " [-0.05637009 -0.04464164 -0.01159501 ... -0.03949338 -0.00797714\n",
      "  -0.08806194]\n",
      " ...\n",
      " [ 0.06350368  0.05068012  0.08864151 ...  0.07120998  0.02929656\n",
      "   0.07348023]\n",
      " [-0.10722563 -0.04464164 -0.01159501 ...  0.03430886  0.00702714\n",
      "  -0.03007245]\n",
      " [ 0.02717829 -0.04464164  0.04984027 ...  0.05275942 -0.05296264\n",
      "  -0.0052198 ]]\n",
      "[104. 137. 190. 220. 171.  70. 128. 292. 178. 127. 310. 150.  39.  65.\n",
      " 110.  53.  71.  77.  47. 175. 275. 283.  77.  97.  92. 258.  66. 202.\n",
      " 230. 220. 182. 103. 217. 277. 281. 142.  63. 137.  90. 139.  63. 140.\n",
      " 332.  71. 225.  93. 268.  99.  88. 182. 232. 162. 293.  90.  71.  51.\n",
      "  77. 124. 190. 152. 212. 115. 116. 179.  96. 139. 192.  42. 180. 111.\n",
      " 177.  81. 198. 131. 230. 197.  64. 321. 275. 214. 210. 122. 141. 121.\n",
      " 191. 126. 168. 277. 111.  68. 265. 172. 129.  84. 153. 174. 252. 196.\n",
      " 196. 185. 262. 104. 168. 113. 232. 186. 346.  65. 261.  51.  72.  55.\n",
      "  55. 156.  84. 265. 199. 135.  69.  68. 180. 170.  48. 170. 155. 132.\n",
      "  55.  83. 107.  78. 281. 144. 235. 242.  49. 109. 114. 198.  80.  75.\n",
      "  95. 263. 179. 109. 281. 198.  59. 174.  81.  72. 310. 140.  48. 257.\n",
      " 244. 183. 248. 185.  64. 109. 152.  96.  87. 221.  91.  99.  42.  37.\n",
      " 163. 129. 262.  53. 178.  95. 178.  52.  63.  78.  83. 214.  85. 143.\n",
      "  74. 195.  69. 243. 241. 258.  40. 101. 249. 202.  97. 154. 259.  55.\n",
      " 102. 200. 276.  83.  65. 151. 111. 173.  39. 341. 202. 197. 206. 144.\n",
      " 155. 336.  25. 246.  90. 215. 237.  72. 264. 200. 144.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/leodom01/Repos/ai-privacy-DataProtectionTechonolgies')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "dataset = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.5, random_state=14)\n",
    "\n",
    "features = ['age', 'sex', 'bmi', 'bp',\n",
    "                's1', 's2', 's3', 's4', 's5', 's6']\n",
    "QI = ['age', 'bmi', 's2', 's5', 's6']\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DecisionTreeRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy (R2 score):  0.15014421352446072\n"
     ]
    }
   ],
   "source": [
    "from apt.minimization import GeneralizeToRepresentative\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model1 = DecisionTreeRegressor(random_state=10, min_samples_split=2)\n",
    "model1.fit(X_train, y_train)\n",
    "print('Base model accuracy (R2 score): ', model1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run minimization\n",
    "We will try to run minimization with only a subset of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy of model on generalized data, relative to original model predictions (base generalization derived from tree, before improvements): 0.108922\n",
      "Improving accuracy\n",
      "feature to remove: s5\n",
      "Removed feature: s5, new relative accuracy: 0.505498\n",
      "feature to remove: bmi\n",
      "Removed feature: bmi, new relative accuracy: 0.716972\n",
      "Accuracy on minimized data:  0.1116122925781402\n",
      "generalizations:  {'ranges': {'age': [-0.07090024650096893, -0.043656209483742714, -0.041839939542114735, -0.03639113181270659, -0.01459590089507401, -0.012779632292222232, -0.009147093165665865, -0.0036982858437113464, 0.03989217430353165, 0.039892176166176796, 0.05623859912157059, 0.06713621318340302], 's2': [-0.0550188384950161, -0.0285577941685915, -0.024643437936902046, -0.02135537937283516, -0.013683241792023182, -0.006480826530605555, 0.009176596067845821, 0.023111702874302864, 0.02420772146433592, 0.02655633445829153, 0.039082273840904236], 's6': [-0.052854035049676895, -0.03835666086524725, -0.02593033987795934, -0.021788232028484344, -0.01350401807576418, -0.003148751042317599, 0.005135462852194905, 0.01756178360665217, 0.021703890524804592, 0.02998810407007113, 0.03205915819853544, 0.0486275851726532]}, 'categories': {}, 'untouched': ['s4', 'bmi', 'sex', 's5', 's3', 'bp', 's1'], 'category_representatives': {}, 'range_representatives': {'age': [-0.07090024650096893, -0.09269547780327612, -0.04910501639104307, 0.0027244038647040725, -0.03820740103798481, -0.027309785684926546, 0.0018162695632781833, -0.009147093429829445, 0.021795230073621497, 0.009015598825267658, 0.008173211477696896, 0.04170844488444244], 's2': [-0.0550188384950161, -0.07239857825244314, -0.03607335668485709, -0.02480001206043385, -0.02448686359864431, -0.014466112821379181, 0.007828711299225688, 0.00463594334778245, 0.019667069513680118, 0.024051147978733624, 0.02499059336410222], 's6': [-0.052854035049676895, -0.06735140813781726, -0.04664087356364498, -0.03835665973397607, -0.025930338989472702, -0.013504018244969336, -0.009361911330134878, -0.0010776975004659671, 0.0113486232440374, 0.004142106772633269, 0.02377494398854077, 0.03205915781820968]}}\n"
     ]
    }
   ],
   "source": [
    "# note that is_regression param is True\n",
    "\n",
    "minimizer1 = GeneralizeToRepresentative(model1, target_accuracy=0.7, is_regression=True,\n",
    "                                    features_to_minimize=QI)\n",
    "\n",
    "# Fitting the minimizar can be done either on training or test data. Doing it with test data is better as the\n",
    "# resulting accuracy on test data will be closer to the desired target accuracy (when working with training\n",
    "# data it could result in a larger gap)\n",
    "# Don't forget to leave a hold-out set for final validation!\n",
    "X_generalizer_train1, x_test1, y_generalizer_train1, y_test1 = train_test_split(X_test, y_test,\n",
    "                                                                test_size = 0.4, random_state = 38)\n",
    "\n",
    "x_train_predictions1 = model1.predict(X_generalizer_train1)\n",
    "minimizer1.fit(X_generalizer_train1, x_train_predictions1, features_names=features)\n",
    "transformed1 = minimizer1.transform(x_test1, features_names=features)\n",
    "print('Accuracy on minimized data: ', model1.score(transformed1, y_test1))\n",
    "print('generalizations: ',minimizer1.generalizations)#%% md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy (R2 score):  0.5080563960651392\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from apt.minimization import GeneralizeToRepresentative\n",
    "\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train, y_train)\n",
    "print('Base model accuracy (R2 score): ', model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run minimization\n",
    "We will try to run minimization with only a subset of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy of model on generalized data, relative to original model predictions (base generalization derived from tree, before improvements): 0.201734\n",
      "Improving accuracy\n",
      "feature to remove: s5\n",
      "Removed feature: s5, new relative accuracy: 0.292914\n",
      "feature to remove: age\n",
      "Removed feature: age, new relative accuracy: 0.291507\n",
      "feature to remove: s2\n",
      "Removed feature: s2, new relative accuracy: 0.947873\n",
      "Accuracy on minimized data:  0.46523158691549726\n",
      "generalizations:  {'ranges': {'bmi': [-0.0660245232284069, -0.06171327643096447, -0.048779530450701714, -0.04770171828567982, -0.036923596635460854, -0.022912041284143925, -0.01644516922533512, -0.015906263142824173, -0.009978296235203743, 0.007266696775332093, 0.022356065921485424, 0.028822937980294228, 0.04499012045562267, 0.053073709830641747, 0.10103634744882584], 's6': [-0.07356456853449345, -0.052854035049676895, -0.048711927607655525, -0.046640874817967415, -0.044569820165634155, -0.0383566590026021, -0.021788232028484344, -0.017646125052124262, -0.013504017610102892, -0.0031487508676946163, 0.02377494378015399, 0.06519601307809353, 0.08383549377322197]}, 'categories': {}, 'untouched': ['s4', 'sex', 's5', 'age', 's3', 'bp', 's2', 's1'], 'category_representatives': {}, 'range_representatives': {'bmi': [-0.0660245232284069, -0.09027529589850945, 0.006466872990131378, -0.05794093368208547, 0.005389060825109482, -0.04392937672163507, -0.03099563183506548, -0.022373135244019075, 0.002963983453810215, -0.015906262800734303, -0.002972517914164677, 0.0175059114895705, 0.028284032228378497, 0.030439656376140087, 0.04768464955823289], 's6': [-0.07356456853449345, -0.092204049626824, -0.05906719430814835, 0.0010355263948440552, 0.0010355273261666298, -0.04664087356364498, -0.03835665973397607, -0.025930338989472702, -0.01764612515980379, -0.013504018244969336, -0.009361911330134878, 0.0030644094143684884, 0.040343371647878594]}}\n"
     ]
    }
   ],
   "source": [
    "# note that is_regression param is True\n",
    "\n",
    "minimizer2 = GeneralizeToRepresentative(model2, target_accuracy=0.7, is_regression=True,\n",
    "                                    features_to_minimize=QI)\n",
    "\n",
    "# Fitting the minimizar can be done either on training or test data. Doing it with test data is better as the\n",
    "# resulting accuracy on test data will be closer to the desired target accuracy (when working with training\n",
    "# data it could result in a larger gap)\n",
    "# Don't forget to leave a hold-out set for final validation!\n",
    "X_generalizer_train2, x_test2, y_generalizer_train2, y_test2 = train_test_split(X_test, y_test,\n",
    "                                                                test_size = 0.4, random_state = 38)\n",
    "\n",
    "x_train_predictions2 = model2.predict(X_generalizer_train2)\n",
    "minimizer2.fit(X_generalizer_train2, x_train_predictions2, features_names=features)\n",
    "transformed2 = minimizer2.transform(x_test2, features_names=features)\n",
    "print('Accuracy on minimized data: ', model2.score(transformed2, y_test2))\n",
    "print('generalizations: ',minimizer2.generalizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
