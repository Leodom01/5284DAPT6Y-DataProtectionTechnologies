{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying data minimization to a trained ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will show how to perform data minimization for ML models using the minimization module. \n",
    "\n",
    "This will be demonstarted using the Adult dataset (original dataset can be found here: https://archive.ics.uci.edu/ml/datasets/adult). \n",
    "\n",
    "We use only the numerical features in the dataset because this is what is currently supported by the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.9000e+01 1.3000e+01 2.1740e+03 0.0000e+00 4.0000e+01]\n",
      " [5.0000e+01 1.3000e+01 0.0000e+00 0.0000e+00 1.3000e+01]\n",
      " [3.8000e+01 9.0000e+00 0.0000e+00 0.0000e+00 4.0000e+01]\n",
      " ...\n",
      " [5.8000e+01 9.0000e+00 0.0000e+00 0.0000e+00 4.0000e+01]\n",
      " [2.2000e+01 9.0000e+00 0.0000e+00 0.0000e+00 2.0000e+01]\n",
      " [5.2000e+01 9.0000e+00 1.5024e+04 0.0000e+00 4.0000e+01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Use only numeric features (age, education-num, capital-gain, capital-loss, hours-per-week)\n",
    "x_train = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "                        usecols=(0, 4, 10, 11, 12), delimiter=\",\")\n",
    "\n",
    "y_train = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "                        usecols=14, dtype=str, delimiter=\",\")\n",
    "\n",
    "\n",
    "x_test = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n",
    "                        usecols=(0, 4, 10, 11, 12), delimiter=\",\", skiprows=1)\n",
    "\n",
    "y_test = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n",
    "                        usecols=14, dtype=str, delimiter=\",\", skiprows=1)\n",
    "\n",
    "# Trim trailing period \".\" from label\n",
    "y_test = np.array([a[:-1] for a in y_test])\n",
    "\n",
    "y_train[y_train == ' <=50K'] = 0\n",
    "y_train[y_train == ' >50K'] = 1\n",
    "y_train = y_train.astype(int)\n",
    "\n",
    "y_test[y_test == ' <=50K'] = 0\n",
    "y_test[y_test == ' >50K'] = 1\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy:  0.8193599901725939\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from apt.utils.datasets import ArrayDataset\n",
    "from apt.utils.models import SklearnClassifier, ModelOutputType\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "base_est = DecisionTreeClassifier()\n",
    "model = SklearnClassifier(base_est, ModelOutputType.CLASSIFIER_PROBABILITIES)\n",
    "model.fit(ArrayDataset(x_train, y_train))\n",
    "\n",
    "print('Base model accuracy: ', model.score(ArrayDataset(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run minimization\n",
    "We will try to run minimization with different possible values of target accuracy (how close to the original model's accuracy we want to get, 1 being same accuracy as for original data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy of model on generalized data, relative to original model predictions (base generalization derived from tree, before improvements): 0.927073\n",
      "Improving accuracy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_train_predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     26\u001b[0m     x_train_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(x_train_predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mminimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mArrayDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_generalizer_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_predictions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m transformed \u001b[38;5;241m=\u001b[39m minimizer\u001b[38;5;241m.\u001b[39mtransform(dataset\u001b[38;5;241m=\u001b[39mArrayDataset(x_test))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy on minimized data: \u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m.\u001b[39mscore(ArrayDataset(transformed, y_test)))\n",
      "File \u001b[0;32m~/Repos/ai-privacy-DataProtectionTechonolgies/apt/minimization/minimizer.py:389\u001b[0m, in \u001b[0;36mGeneralizeToRepresentative.fit\u001b[0;34m(self, X, y, features_names, dataset)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImproving accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m accuracy \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_accuracy:\n\u001b[0;32m--> 389\u001b[0m     removed_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remove_feature_from_generalization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_prepared_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneralize_using_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m removed_feature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/ai-privacy-DataProtectionTechonolgies/apt/minimization/minimizer.py:963\u001b[0m, in \u001b[0;36mGeneralizeToRepresentative._remove_feature_from_generalization\u001b[0;34m(self, original_data, prepared_data, nodes, labels, feature_data, current_accuracy, generalize_using_transform)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_remove_feature_from_generalization\u001b[39m(\u001b[38;5;28mself\u001b[39m, original_data, prepared_data, nodes, labels, feature_data,\n\u001b[1;32m    960\u001b[0m                                         current_accuracy, generalize_using_transform):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# prepared data include one hot encoded categorical data,\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;66;03m# if there is no categorical data prepared data is original data\u001b[39;00m\n\u001b[0;32m--> 963\u001b[0m     feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_feature_to_remove\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepared_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mcurrent_accuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneralize_using_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    966\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/ai-privacy-DataProtectionTechonolgies/apt/minimization/minimizer.py:987\u001b[0m, in \u001b[0;36mGeneralizeToRepresentative._get_feature_to_remove\u001b[0;34m(self, original_data, prepared_data, nodes, labels, feature_data, current_accuracy, generalize_using_transform)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generalizations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muntouched\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generalize_using_transform:\n\u001b[0;32m--> 987\u001b[0m         feature_ncp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_ncp_for_feature_from_cells\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    989\u001b[0m         feature_ncp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_ncp_numeric(ranges[feature],\n\u001b[1;32m    990\u001b[0m                                              range_counts[feature],\n\u001b[1;32m    991\u001b[0m                                              feature_data[feature],\n\u001b[1;32m    992\u001b[0m                                              total)\n",
      "File \u001b[0;32m~/Repos/ai-privacy-DataProtectionTechonolgies/apt/minimization/minimizer.py:1047\u001b[0m, in \u001b[0;36mGeneralizeToRepresentative._calculate_ncp_for_feature_from_cells\u001b[0;34m(self, feature, feature_data, samples_pd)\u001b[0m\n\u001b[1;32m   1045\u001b[0m feature_ncp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcells:\n\u001b[0;32m-> 1047\u001b[0m     count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_record_count_for_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_pd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m     generalizations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_generalizations_for_cell(cell)\n\u001b[1;32m   1049\u001b[0m     cell_ncp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Repos/ai-privacy-DataProtectionTechonolgies/apt/minimization/minimizer.py:600\u001b[0m, in \u001b[0;36mGeneralizeToRepresentative._get_record_count_for_cell\u001b[0;34m(self, x, cell, mapped)\u001b[0m\n\u001b[1;32m    598\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, (_, row) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(x\u001b[38;5;241m.\u001b[39miterrows()):\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mapped\u001b[38;5;241m.\u001b[39mitem(index) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cell_contains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapped\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    601\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m count\n",
      "File \u001b[0;32m~/Repos/ai-privacy-DataProtectionTechonolgies/apt/minimization/minimizer.py:607\u001b[0m, in \u001b[0;36mGeneralizeToRepresentative._cell_contains\u001b[0;34m(self, cell, row, index, mapped)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_features):\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m cell[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mranges\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 607\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cell_contains_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mranges\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    608\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m cell[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/Repos/ai-privacy-DataProtectionTechonolgies/apt/minimization/minimizer.py:655\u001b[0m, in \u001b[0;36mGeneralizeToRepresentative._cell_contains_numeric\u001b[0;34m(index, range, row)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cell_contains_numeric\u001b[39m(index, \u001b[38;5;28mrange\u001b[39m, row):\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;66;03m# convert row to ndarray to allow indexing\u001b[39;00m\n\u001b[1;32m    654\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(row)\n\u001b[0;32m--> 655\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mrange\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    657\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from apt.minimization import GeneralizeToRepresentative\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# default target_accuracy is 0.998\n",
    "minimizer = GeneralizeToRepresentative(model)\n",
    "\n",
    "# Feature names for X\n",
    "feature_names = ['age', 'edu-level', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "# Create a dictionary to map feature names to their corresponding indices\n",
    "feature_name_map = {name: idx for idx, name in enumerate(feature_names)}\n",
    "\n",
    "# Fitting the minimizar can be done either on training or test data. Doing it with test data is better as the \n",
    "# resulting accuracy on test data will be closer to the desired target accuracy (when working with training \n",
    "# data it could result in a larger gap)\n",
    "# Don't forget to leave a hold-out set for final validation!\n",
    "X_generalizer_train, x_test, y_generalizer_train, y_test = train_test_split(x_test, y_test, stratify=y_test,\n",
    "                                                                test_size = 0.4, random_state = 38)\n",
    "\n",
    "\n",
    "# Set feature names for your X_generalizer_train dataset\n",
    "X_generalizer_train_with_names = ArrayDataset(X_generalizer_train)\n",
    "\n",
    "x_train_predictions = model.predict(ArrayDataset(X_generalizer_train))\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "print(x_test)\n",
    "print(y_test)\n",
    "print(x_train_with_names)\n",
    "print(x_train_predictions)\n",
    "\n",
    "if x_train_predictions.shape[1] > 1:\n",
    "    x_train_predictions = np.argmax(x_train_predictions, axis=1)\n",
    "minimizer.fit(dataset=ArrayDataset(X_generalizer_train, x_train_predictions))\n",
    "transformed = minimizer.transform(dataset=ArrayDataset(x_test))\n",
    "\n",
    "print('Accuracy on minimized data: ', model.score(ArrayDataset(transformed, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see what features were generalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ranges': {}, 'categories': {}, 'untouched': ['3', '2', '4', '0', '1'], 'category_representatives': {}, 'range_representatives': {}}\n"
     ]
    }
   ],
   "source": [
    "generalizations = minimizer.generalizations\n",
    "print(generalizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the default target accuracy of 0.998 of the original accuracy, no generalizations are possible (all features are left untouched, i.e., not generalized).\n",
    "\n",
    "Let's change to a slightly lower target accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy of model on generalized data, relative to original model predictions (base generalization derived from tree, before improvements): 0.927063\n",
      "Improving accuracy\n",
      "feature to remove: 2\n",
      "Removed feature: 2, new relative accuracy: 0.931542\n",
      "feature to remove: 0\n",
      "Removed feature: 0, new relative accuracy: 0.934101\n",
      "feature to remove: 1\n",
      "Removed feature: 1, new relative accuracy: 0.952015\n",
      "feature to remove: 4\n",
      "Removed feature: 4, new relative accuracy: 0.995521\n",
      "Accuracy on minimized data:  0.8115886415963162\n",
      "{'ranges': {'3': [690.0, 782.0, 1526.0, 1588.0, 1665.0, 1779.5, 1824.5, 1978.5]}, 'categories': {}, 'untouched': ['0', '1', '2', '4'], 'category_representatives': {}, 'range_representatives': {'3': [690.0, 0.0, 372.0, 1421.0, 1564.0, 1590.0, 1740.0, 77.0]}}\n"
     ]
    }
   ],
   "source": [
    "# We allow a 1% deviation in accuracy from the original model accuracy\n",
    "minimizer2 = GeneralizeToRepresentative(model, target_accuracy=0.99)\n",
    "\n",
    "minimizer2.fit(dataset=ArrayDataset(X_generalizer_train, x_train_predictions))\n",
    "transformed2 = minimizer2.transform(dataset=ArrayDataset(x_test))\n",
    "print('Accuracy on minimized data: ', model.score(test_data=ArrayDataset(transformed2, y_test)))\n",
    "generalizations2 = minimizer2.generalizations\n",
    "print(generalizations2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we were able to generalize one feature, feature number 3 (capital-loss)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
